[{"sklearn.linear_model.LinearRegression()": "llama a la clase LinearRegression, esta clase representa un modelo de regresion lineal que se usa para predecir valores.", "sklearn.linear_model.LogisticRegression()": "llama a la clase LogisticRegression, esta clase representa un modelo de regresion lineal que se usa para clasificar valores.", "any_instance.fit(X_train,y_train)": "metodo que toma los datos para entrenar el modelo(general).", "any_instance.predict(X_test)": "metodo que toma datos nuevos y hace predicciones a partir de haber sido entrenado(general).", "sklearn.model_selection.train_test_split(*arrays, test_size,train_size,random_state=0)": "esta funcion nos permite splitear separar los datos para training y los datos para test de nuestro modelo, los size deben ser en floats de 0 hatsta 1(si no se especifica train_size rellena lo que le fale a test_size); devuelve una tupla de 4 elementos(X_train,X_test,y_train,y_test).", "sklearn.tree.DecisionTreeClassifier(random_state=0)": "llama la clase DecisionTreeClassifier, esta clase es para un arbol de decision; max_features= can be used to limit the number of features considered at each node;max_depth= profundidad del modelo, maximo 3.", "sklearn.datasets.make_regression(n_samples,n_features,noise)": "funcion que se usa para crear datasets,n_samples=: size de cada 1d array; n_feaures=: numero de columnas; noise=: hace referencia a valores incorrecos como nan.", "sklearn.metrics.accuracy_score(true_results,model_results)": "para calcular accuarcy, precision general lograda por el modelo.", "sklearn.metrics.precision_score(true_results,model_results)": "para calcular precision, porciento de valores realmente True de los True determinados por el modelo.", "sklearn.metrics.recall_score(true_results,model_results)": "para calcular recall, porciento de valores labeleados como True por el modelo de los True correctos.", "sklearn.metrics.f1_score(true_results,model_results)": "para calcular f1-score, balance entre precision_score y recall_score.", "sklearn.metrics.confusion_matrix(true_results,model_results)": " para calcular confusion-matrix que muestra los aciertos y fallos del modelo de la forma [[TP,FP],[FN,TN]].", "sklearn.metrics.mean_squared_error(true_resuls,model_results)": "para calcular mean squared error.", "sklearn.metrics.r2_score(true_resuls,model_results)": "para calcular r2_score.", "sklearn.impute.SimpleImputer()": "para imputear de forma general en un df para no tener que hacerlo manual por cada columna; strategy='mean'(default) se especifica con que llenar; missing_values=np.nan(default) valores a llenar.Se le pasa fit() con los valores a aprender a rellenar y se usa transform() y se guarda en los valores a remplazar(simplificado en un solo paso con fit_transform())(mas en documentacion).", "sklearn.ensemble.RandomForestClassifier(n_estimators=)": "is a meta estimator that fits a number of decision tree classifiers on various sub-samples of the dataset and uses averaging to improve the predictive accuracy and control over-fitting, n_stimators=100(default).", "sklearn.preprocessing.OneHotEncoder()": "clase para transformar columnascuyo objetivo principal es hacer lo mismo que el pd.get_dummies pero ya devolver los valores en 0 y 1 para que puedan ser procesados; inst.fit_transform(rango) para entranar y transformar las columnas; toarray() para transformar lo que devuelva el metodo fit a un array; inst.get_feature_names_out() devuelve los nombres de como quedarian las columnas after transform.", "sklearn.preprocessing.StandardScaler()": "normalize the dataset to ensure that all features are on a similar scale. This step is crucial for logistic regression, as it helps prevent certain features from dominating the others in the model's learning process;fit_transform() entrena al modelo y tansforma.", "sklearn.datasets.make_classification(n_samples=, n_features=, random_state=)": "same as make_regression.", "sklearn.model_selection.KFold(n_splits=)": "para cross-validation;n_splits=(default =5) en cuanas partes dividr el dataset; inst.split(features(x),tarjet(y)): devuelve una tupla de dos indices que son los utilizados por la clase para dividr el dataset.", "sklearn.model_selection.cross_val_score(model, features, target)": "funcion que resume la clase kfold para cross-validation; en model le pasamos el modelo o la instancia de este; cv= cant de partes a dividir el k-fold(default=3-5),scoring= scorer que le vamos a pasar al cross validation(default=mean)", "sklearn.metrics.make_scorer(function)": "para convertir una funcion de scorer a un scorer y poder ser utilizados dentro de otras como cross-validation.", "sklearn.model_selection.validation_curve(model, features, target, param_name=, param_range=)": "para testear un modelo con disintos parametros; model or inst del model;param_name= hyperparametro a tunniar(testear); param_range= rango  de valores a testear con el hyperparametro; cv = cuantas partes dividir(default=None);scoring= definir que scores pasar a cada fold; devuelve una tupla de train_scores and test_scores.", "sklearn.svm.SVC()": "Support Vector Machine, ta poente, revisar documentacion.", "sklearn.model_selection.GridSearchCV(df,param_grid)": "hyperparameters tunning,is a process that searches exhaustively through a manually specified subset of the hyperparameter space of the targeted algorithm; como param_grid debemos especificar en un dicc de forma {param: rango de parametros} los rangos para los hyper a tuniar,cv= cuantos folds(default=None); metodo fit con X_train and y_train; atributo best_estimator_ devuelve el estimator con el que se obtuvo los mejores resultados.", "sklearn.model_selection.RandomizedSearchCV(dt, param_grid)": "same as GridSearchCV pero este busca de forma random y es mas rapido pero no tan bueno.", "sklearn.datasets.make_blobs(n_samples,centers)": "para crear datasets sinteticos, devuelve una tupla X,y ya spliteado el dataset; s_samples= cant de rows; centers= en cuantos pedazos dividir el df. ", "sklearn.tree.tree_plot(modelo,filled=True)": "para plotear las ramas y hojas de un arbol de decision y ver su funcionamiento interno."}]